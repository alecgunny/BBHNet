# commented args represent values filled out
# by train task at run time. To build a functional
# standalone config, add these in

model:
  # architecture
  arch:
    class_path: aframe.architectures.ConvolutionalAutoencoder
    init_args:
      encode_channels: [64, 128, 256, 512, 1024]
      kernel_size: 7
      stride: 2
      skip_connection:
        class_path: aframe.architectures.autoencoder.ConcatSkipConnect
      activation:
        class_path: torch.nn.ReLU
      output_activation:
        class_path: torch.nn.Identity
  metric:
    class_path: train.validation.TimeSlideAUROC
    init_args:
      max_fpr: 1e-3
      pool_length: 8
  loss_fn:
    class_path: train.metrics.MatchedFilterLoss
    init_args:
      max_shift: 0.005
      chisq_num_bins: 8
      chisq_penalty: 100
      lowpass_cutoff: null
      lowpass_penalty: 0

data:
  # loading args
  # data_dir:
  # ifos:

  # preprocessing args
  batch_size: 768
  kernel_length: 1
  psd_length: 8
  fduration: 1
  highpass: 32
  fftlength: null

  # augmentation args
  snr_thresh: 40
  max_snr: 100
  snr_alpha: 3
  trigger_pad: 0

  # validation args
  valid_frac: 0.25
  valid_stride: 0.5
  num_valid_views: 4
  valid_livetime: 86400
optimizer:
  lr: 0.08
lr_scheduler:
  pct_start: 0.115
trainer:
  # by default, use a local CSV logger.
  # Options in train task for using a
  # wandb logger instead
  logger:
    - class_path: lightning.pytorch.loggers.CSVLogger
      init_args:
        # save_dir:
        flush_logs_every_n_steps: 10
  # devices:
  # strategy: set to ddp if len(devices) > 1
  precision: 16-mixed
  accelerator: auto
  max_epochs: 100
  check_val_every_n_epoch: 1
  log_every_n_steps: 20
  benchmark: true
